{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <center> Assignment - Week 3\n",
        "### <center> Total:- 60 Points (50 Questions, 10 Presentation)"
      ],
      "metadata": {
        "id": "NCnD9mkPavgU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nix_AYvRaiUk"
      },
      "outputs": [],
      "source": [
        "###### IMPORTANT ########\n",
        "Your_Name = \" \"\n",
        "Your_Email_id = \" \""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "LLt-eFoGa5cX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q1 [5 Points] \n",
        "***Which of the following is not an activation function?***\n",
        "\n",
        "* *a - Sigmoid function*\n",
        "* *b - Hyperbolic tangent function*\n",
        "* *c - Rectified linear unit (RELU) function*\n",
        "* *d - Leaky RELU function*\n",
        "* *e - dynamic function*\n",
        "* *f - Maxout function*\n",
        "* *g - gaussian function*\n",
        "* *h - sobel function*\n",
        "* *i - Exponential Linear unit (ELU) function*"
      ],
      "metadata": {
        "id": "QIaQdZWwbOYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Soln - 1\n",
        "\n",
        "# Print the correct options here\n",
        "print(\" \")"
      ],
      "metadata": {
        "id": "WDelv5FcbhWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q2 [3 Points]\n",
        "***Suppose a neuron N in layer 2 has 5 input neurons from layer 1. Do all these 5 input neurons have the same contribution towards the output of the neuron N?Explain briefly.***"
      ],
      "metadata": {
        "id": "SSNmiO1VbiHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Soln - 2\n",
        "\n",
        "# Print your answer below\n",
        "print(\"\"\" \"\"\")"
      ],
      "metadata": {
        "id": "gP0YCd-Jb017"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q3 [4 Points]\n",
        "***Organise below points in right sequence:-***\n",
        "- *Dataset capturing*\n",
        "- *Optimizing parameters with backpropagation*\n",
        "- *Predicting the final output using our model*\n",
        "- *Data preprocessing*\n",
        "- *Calculating loss function*\n",
        "- *Applying activation function on initial output*\n",
        "- *Initializing weights and biases*"
      ],
      "metadata": {
        "id": "-nQq3jDdb9_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Soln - 3\n",
        "\n",
        "# Print the right sequence below\n",
        "print(\"\"\"Corerct Sequence:-\n",
        "- \n",
        "- \n",
        "-\n",
        "-\n",
        "-\n",
        "-\n",
        "-                                       \"\"\")"
      ],
      "metadata": {
        "id": "VUUEMoJlcUqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q4 [6 Points] \n",
        "\n",
        "***Answer the following questions -*** \n",
        "\n",
        "**a.** *Why is normalization done in batches?* \n",
        "\n",
        "**b.** *When is it suitable to use batches?* \n",
        "\n",
        "**c.** *Can we do normalization without batches? If yes, in which case?*"
      ],
      "metadata": {
        "id": "3eLrhsercTqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Soln - 4\n",
        "\n",
        "# Write you answers below\n",
        "\n",
        "a = \"\"\" \"\"\"\n",
        "\n",
        "b = \"\"\" \"\"\"\n",
        "\n",
        "c = \"\"\" \"\"\"\n",
        "\n",
        "# Dont change the line below\n",
        "print(f\"a)\\n{a}\\n\\nb)\\n{b}\\n\\nc)\\n{c}\")"
      ],
      "metadata": {
        "id": "S23LvNw0c6Nx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q5 [4 Points]\n",
        "***Which propogation pass helps you to -***\n",
        "\n",
        "**a.** *Obtain network output?*\n",
        "\n",
        "**b.** *Update weights?*\n",
        "\n",
        "**c.** *Calculate gradients?*\n",
        "\n",
        "**d.** *Calculate loss?*"
      ],
      "metadata": {
        "id": "wlizwgtYdjAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Soln - 5 (Type your answers as either 'Forward' or 'Backward'.)\n",
        "\n",
        "a = \" \"\n",
        "b = \" \"\n",
        "c = \" \"\n",
        "d = \" \"\n",
        " \n",
        "# Dont change the line below\n",
        "print(f\"a)\\n{a}\\n\\nb)\\n{b}\\n\\nc)\\n{c}\\n\\nd){d}\")"
      ],
      "metadata": {
        "id": "P-iuwb_peA9u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q6) [5 Points]    \n",
        "**a)** *What do you understand by the term 'outlier'?*\n",
        "\n",
        "**b)** *Does the following image have outliers? Explain your answer.*       \n",
        "<img src = \"https://drive.google.com/uc?id=1Z4jr2NBtSWu0eoYTdux0p3BOlrb7DI3Q\" width = 400 height = 300>\n",
        "       \n",
        "**c)** *Is linear regression sensitive to outliers? Use the image in (b) or your own example to explain it graphically.*      "
      ],
      "metadata": {
        "id": "8DKNc3MGhHcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Soln - 6\n",
        "\n",
        "# a\n",
        "print(\"\"\"a) \"\"\")\n",
        "\n",
        "# b\n",
        "print(\"\"\"\\nb) \"\"\")\n"
      ],
      "metadata": {
        "id": "3L28a60nhPUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**soln c)** *Manually upload the image(s) you made to explain it graphically (Graph(s) made on paint shall work!)*\n",
        "\n",
        "**Make sure that the image is visible before you submit!**\n",
        " \n",
        ".      \n",
        ".      \n",
        ".     \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "17JnOllDhOyq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q7) [3 Points]\n",
        "***Which of the two graphs given below is for sigmoid function? Explain the reason for your choice along with the correct formula.*** \n",
        "\n",
        "*Graph 1:-*     \n",
        "<img src = \"https://drive.google.com/uc?id=1MKeJAiUpPYTDQ0OHar60YmBI7BVpl-9J\">\n",
        "\n",
        "*Graph 2:-*      \n",
        "<img src = \"https://drive.google.com/uc?id=1RYFG5rZ4mO2n52ohWmWTFgehmc30KBqd\">"
      ],
      "metadata": {
        "id": "WXdof8BQiBVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Soln - 7\n",
        "\n",
        "# Print Graph 1 or Graph 2 whichever option you find is correct\n",
        "print(\" \")\n",
        "\n",
        "# Explain the reason \n",
        "print(\" \")\n",
        "\n",
        "# Print the formula of sigmoid function\n",
        "print(\"Ïƒ(x) = \")"
      ],
      "metadata": {
        "id": "Weq6YSDJiMDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q8) [20 Points]\n",
        "***You will be training a Logistic Regression Model from scratch in this question!***\n",
        "\n",
        "**Data:-**\n",
        "- X_train:- Compute 500 random values between 0 to 2 (both inclusive).\n",
        "- X_test:- Compute 100 random values between 0 to 2 (both inclusive).\n",
        "- *Generate y_train and y_test data using the equation:* $y = \\frac{1 - e^{-x}}{1 + e^{-x}}$\n",
        "\n",
        "**Note:-** \n",
        "- *Accurate predictions will be judged on the basis of the difference between predicted and original y values.*\n",
        "- *Each time we run your code it should give the same result of output!*\n",
        "\n",
        "**Outputs should be similar to:-**    \n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=14Fak-0Xa9s1LHBlbNr-90SYR0clmE3D-\">\n",
        "\n",
        "**Use below helper functions or create your own functions to train your logistic regression model for 5000 iterations and predict values for y and print the 10 most accurate predictions.**\n",
        "\n",
        "```\n",
        "# Functions that will be needed while training the logisitc regression\n",
        "def sigmoid(X):\n",
        "    '''Converts all the input values in between 0 to 1'''\n",
        "    return 1 / (1 + np.exp(-X)) \n",
        "\n",
        "def predict(X, W, b):\n",
        "    '''On the test set we will apply the sigmoid on the input to get the predicted targets'''\n",
        "    return sigmoid(W*X + b)\n",
        "\n",
        "def compute_cost(X, y, W, b):\n",
        "    '''To generate the avg cost after each iteration in forward propagation'''\n",
        "    observations = len(y)                                                       # Total records in the data\n",
        "    predictions = predict(X, W, b)                                              # Predicted output after forward pass\n",
        "    cost = (-y*np.log(predictions)) - ((1-y)*np.log(1-predictions))             # Computing cost for every training vals\n",
        "    cost = cost.sum() / observations                                            # Average cost\n",
        "    return cost\n",
        "\n",
        "def update_weights(X, y, W,b, learning_rate):\n",
        "    '''Compute the gradients of cost function wrt to theta or say weights and bias and update weights using gradient descent'''\n",
        "    predictions = predict(X, W, b)                                              # Predicted output after forward pass\n",
        "    m, n = X.shape                                                              # m = total records of x\n",
        "    err = (predictions - y)                                                     # Error between predicted and actual output   \n",
        "    err = np.reshape(err, m)                                                    # Reshaping for matrix multiplications\n",
        "    gradient = np.dot(X.T,  err)                                                # dJ/d(theta) = X.T x err / m\n",
        "    dW = np.dot(X.T, err) / m                                                   # dJ/dw\n",
        "    db = np.sum(err) / m                                                        # dJ/db\n",
        "    W -= learning_rate * dW                                                     # Gradient Descent for weights  \n",
        "    b -= learning_rate * db                                                     # Gradient Descent for bias \n",
        "    '''Returns the updated value after each iteration in back propagation'''\n",
        "    return W, b                                                                 \n",
        "\n",
        "def train(X, y, W, b, learning_rate, iterations):\n",
        "    '''This function will train our model based on learning rate we choose'''\n",
        "    cost_history = []                                                           # We will fill it with cost values after every forward pass\n",
        "    for i in range(iterations):                                                 # For each epoch - Forward + Backward pass \n",
        "        i+=1                                                                    # Adjusting value of epoch \n",
        "        cost = compute_cost(X, y, W, b)                                         # Compute the cost \n",
        "        cost_history.append(cost)                                               # Append it to the list\n",
        "        W, b = update_weights(X, y, W, b, learning_rate)                        # Update the parameters \n",
        "\n",
        "    '''After forward and backward pass, return the final values of weight and bias along with the cost for each epoch'''\n",
        "    return W, b, cost_history                                                     \n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "XXr59cxPiPza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Soln - 8\n",
        "\n",
        "# Code it the way you like it ;)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rfFSMzo_sZcy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}